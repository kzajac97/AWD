import numpy as np
import tensorflow as tf
from tqdm import tqdm as progress_bar


class GenerativeAdversarialNetwork:
    """
    Class holding interface for Generative Adversarial Network
    """
    def __init__(self, generator_build_fn: callable, discriminator_build_fn: callable):
        """
        :param generator_build_fn: function which returns compiled generator model
        :param discriminator_build_fn:  function which returns compiled discriminator model
        """
        super(GenerativeAdversarialNetwork, self).__init__()

        self.generator = generator_build_fn()
        self.discriminator = discriminator_build_fn()

        generator = generator_build_fn()
        discriminator = discriminator_build_fn()

        discriminator.trainable = False

        self.model = tf.keras.Sequential([generator, discriminator, ])

    def compile(self, loss="binary_crossentropy", optimizer=None, **kwargs) -> None:
        """Compile model with default parameters"""
        optimizer = optimizer or tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)
        self.model.compile(loss=loss, optimizer=optimizer, **kwargs)

    def fit(
        self, data_set, latent_dim: int, epochs: int, batch_size: int = 256, callbacks: tuple = (), silent: bool = False
    ) -> None:
        """
        Run Adversarial training of the model

        :param data_set: data set interface object generating desired data set
        :param latent_dim: dimension of latent space used to generate samples
        :param epochs: number of epochs to train for
        :param batch_size: number of data points in single batch
        :param callbacks: list of callbacks to control verbosity and early stopping
        :param silent: if False print progress bar
        """
        n_batches_in_epoch = int(data_set.n_data_points / batch_size)
        for epoch in progress_bar(range(epochs), disable=silent):
            for batch_index in range(n_batches_in_epoch):
                # set-up data batch
                samples = self.generator(data_set.latent_batch(batch_size // 2))
                x, y = data_set.batch(samples, size=batch_size)
                # train discriminator
                discriminator_loss, _ = self.discriminator.train_on_batch(x, y)
                # train generator
                inputs = data_set.latent_batch(size=batch_size, latent_dim=latent_dim)
                labels = np.ones([batch_size, 1])
                generator_loss, _ = self.model.train_on_batch(inputs, labels)

        for callback in callbacks:
            terminate = callback.on_epoch_end(self.generator)
            if terminate:
                return

    def generate(self, samples: np.array) -> np.array:
        """
        :return: return data points generated by the model
        """
        return self.generator(samples)

    def discriminate(self, samples: np.array) -> np.array:
        """
        :return: discrimination result for given samples
        """
        return np.argmanx(self.discriminator.predict(samples), axis=1)

    def discriminate_probability(self, samples: np.array) -> np.array:
        """
        :return: discrimination scores for given samples
        """
        return self.discriminator.predict(samples)
